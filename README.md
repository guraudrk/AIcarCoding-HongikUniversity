# AIcarCoding-HongikUniversity


홍익대학교 공학교육혁신센터에서 주최한 '파이썬을 활용한 인공지능 자율주행차량 제작교육'의 주피터 노트북 코드.

cnn,tensorflow,numpy,사이킷런등의 인공지능을 활용하였다.

0.들어가기 전에

이 readme는 위의 저장된 파일들과 함께 보면 이해가 빠를 것이다.

readme 중간중간에 '자세한 코드는 xxxx파일에 있다'라는 문구를 보면, 그 파일을 연 뒤 readme와 같이 보면 된다. 


1.교육 기간

2024년 07월 15일~ 2024년 07월 19일(1일 6시간,총 30시간)

2.활동

자율주행차를 만들고 코드를 통해 조작하는 활동/cnn을 통해 데이터를 수집해서 그 데이터로 딥러닝 모델을 학습시켜 트랙 위를 자율적으로 주행하게 하는 활동

을 하였다. 다음은 이에 대한 자세한 설명이다.

2.1.자율주행차를 직접 만들어보고 robokitRS라는 라이브러리를 활용해서 자율주행차를 자율적으로 주행하게 하

는 코드를 짜는 활동을 하였다. 

기능을 향상시키기 위해, 초음파센서를 통해 장애물이 있으면 멈추는 기능, 적외선 센서를 활용해 바닥의 색을

탐지해 낭떠러지가 발견이 되면 멈추도록 하는 기능 등을 구현했다.

2.2.

2.1에서 만든 자율주행차를 통해 조이스틱으로(조이스틱 코드가 있음) 트랙을 따라 운전했다.

운전한 데이터를 사진으로 수집한 뒤(자율주행차에 카메라가 달려 있음),

그 사진을 forward,right,left로 데이터 라벨링을 한 뒤 

cnn을 활용하여 모델을 학습 한 뒤  

학습된 모델을 토대로 자율주행차를 트랙에 따라 운전하게 하는 활동을 하였다.



3.자세한 설명

3.1.자율주행차 제작/자율 주행

자세한 코드는 '7월 15일 수업자료'에 있다. readme에서는 방법론적인 것만 설명한다. 

우선 로보로보라는 회사에서 제작한 자율주행차를 조립한다.(조립하는 데에 꽤 시간이 걸린다.)

조립을 하고 나서, 로보로보 회사 사이트에 있는 코드를 통해(주소:https://roborobo.co.kr/eManual/36) 

전진/후퇴/좌회전/우회전하는 코드를 코딩한다. 

이 때, 모듈을 따로 만들어서 import을 통해 언제든지 불러와서 간편하게 사용할 수 있도록 하였다. 

모듈은 저장소의 moblility_module.py에 있다. 

아래는 자세한 코드를 캡쳐한 것이다. 

![모듈 스크린샷](https://github.com/user-attachments/assets/683a6f6b-592e-42f1-8767-6f7113469729)



3.1.1.초음파 센서를 활용하여 장애물을 인식해서 속도를 조절하기

그런 다음 조립할 때 부착했던 초음파 센서를 연결해서, 장애물이 차 바로 앞에 있을 경우 

차를 멈추는 코드를 만들었다.

코드는 다음과 같다. (주피터 노트북에서 일부를 발췌했다.)

"""
#우선 초음파를 이용해서 장애물을 감지하는 코드를 짠다. 

def obstacle():
    #1.초음파센서 포트 연결하기
    rs.sonar_begin(3)
    #2.while문을 이용해서 장애물 탐지
    while 1:
        obstacle = rs.sonar_read(3)
        t.sleep(1) #1초동안...

        print(obstacle)
        if(obstacle<30):
          
            stop() #장애물과 거리가 좁혀지면 멈춘다.
            break

.
.
.
.
.

#앞서 정의한 코드를 바탕으로 장애물을 탐지해서 멈출 수 있도록 한다. 

forward() #앞으로 가는 코드
obstacle() #장애물을 인식하면 멈추는 코드
"""

3.1.2.낭떠러지가 발견이 되면 멈추게 하는 기능

적외선 센서를 통해 바닥의 색을 확인하고 

평범한 길을 벗어나서 낭떠러지가 나오면 멈추도록 하는 기능을 구현했다.

![적외선 센서](https://github.com/user-attachments/assets/e385a360-ad8c-4015-8c31-8412e3328bdb)


3.2.주행 데이터를 수집한 뒤, 데이터 라벨링을 하고 cnn을 통해 모델을 학습시켜 자율주행

(자세한 설명은 'RoboCam 활용'파일에 있다.)

3.2.1.주행 데이터를 수집하기 위해서는 차를 제작할때 설치했던 무선 카메라의 전원을 켜야 한다.

(전원을 키고 끄는 코드는 'RoboCam 활용'파일일에 있다.)

자율주행 실습을 위해 테이프로 트랙을 그린 뒤, 

조이스틱을 조종하는 코드(저장소의 _01_video_joystick_udp_driving코드)를 통해 차를 주행한다. 

차를 주행하게 되면 카메라가 있는데, 카메라가 노선을 탐지해서 트랙을 학습하는 것이다.

(이 때, 조종을 잘 해야 더 좋은 데이터를 얻을 수 있기 때문에, 조종을 잘 해야 한다.)

아래 사진은 ai 차를 조이스틱을 이용해 조종하는 방법이다.

![download](https://github.com/user-attachments/assets/1de1c6b6-8a38-4732-bdae-6276e220a737)

3.2.2.데이터 수집

_02_video_joystick_data_collection.py 파일을 실행시켜, 차량을 주행시킬 때 데이터를 수집한다. 

이 파일을 실행시키면 주행과 동시에 데이터가 폴더에 저장이 되는데, 이 데이터를 학습에 활용하는 것이다.

![download](https://github.com/user-attachments/assets/cbd3018f-d8c9-4380-9399-1c566d458d0b)

![download](https://github.com/user-attachments/assets/f64b184a-2999-4a19-9849-cbd3edcd480f)

3.2.3.이미지 학습

teachable machine이라는 사이트로 들어가서 이미지를 학습시킨다. 

(주소:https://teachablemachine.withgoogle.com/train/image

이 때, forward,left,right의 클래스로 나눠서 학습시킨다.

![download](https://github.com/user-attachments/assets/26fc2a36-596c-4e29-9fc0-5c90e147f19c)

그 다음에 세부 설정을  tensorflow-keras로 설정한 뒤 모델을 내보낸다.

![download](https://github.com/user-attachments/assets/9196f460-3927-48a2-a7d4-804e4310606c)

3.2.4.딥러닝 코드 돌리기

모델을 다운 받으면, 코드들이 있는 파일에 모델을 집어 넣는다. 

그런 다음  _04_cnn_training_4에서 cnn을 실행시킨다. 

참고로, 1주일간 진행된 교육이었으므로 epoch도 많이 적고 데이터도 총 1~2천개 정도밖에 되지 않았다.

![download](https://github.com/user-attachments/assets/5e1a02da-28fd-4d5f-92db-e2a94262bf09)


3.2.5.모델 학습 후 점검

모델 학습을 하면, loss의 그래프를 통해 loss 값이 얼마나 줄어들었나 확인한다.

![download](https://github.com/user-attachments/assets/613e8304-e3d6-4081-96db-3dad8c8544b2)

정확도가 높을 수록 이탈할 확률이 낮아진다. 

마지막으로, 차의 시동을 켜고 트랙 위에 올려 놓은 뒤 _06_ai_driving_thread을 실행시킨다.

주행 동영상은 다음과 같다. 



https://github.com/user-attachments/assets/a80a8e22-bfe2-4781-a50d-c8c93349f3e0



4.느낀 점/미흡했던 점

코딩을 통해 자율주행차를 조작하고, 모델을 학습해서 차를 저절로 주행가능하게 하는 것을 직접 해보니 매우 감명 깊었다. 그리고 그런 과정이 cnn이라는 비교적 쉽고 대중적인 딥러닝 모델을 통해 이뤄졌다는 사실이 매우 흥미로웠다.

하지만, 동영상에서 볼 수 있듯이, 차량의 성능이 완벽하지 않았다. 

이는 연습주행을 통해 데이터를 쌓는 과정이 충분히 이뤄지지 않았고, epoch의 수도 50으로 많지 않았기 때문이다. 


5.교육과정에서 활용한 인공지능

이 교육과정에서 cnn을 주로 사용하였다.(tensorflow,사이킷런 등도 사용하였으나 cnn이 메인이었다.)

![download](https://github.com/user-attachments/assets/a68b75b7-8b3b-4d69-8b8d-9a5d7c762678)

**들어가기 앞서**

cnn과 같은 딥러닝 모델은 자세한 설명을 처음부터 읽으면 헛갈릴 가능성이 높다. 

따라서 선요약을 하겠다.

cnn은 간단히 말해서

'이미지를 백터화 한 다음 합성곱/pooling을 통해 데이터를 핵심만 압축 한 뒤 1차원 배열로 변환해서 분석하는 딥러닝'이다.



자세히 이야기하자면,

CNN(Convolutional Neural Network,합성곱 신경망)은 주로 이미지 인식/처리, 자연어 처리와 같은 데이터의 시

각적 패턴 인식에 사용되는 딥러닝 모델이다. 전통적인 이미지의 공간적 구조를 효율적으로 학습할 수 있다.

CNN에서 단연 돋보이는 것은 바로 합성곱이다. 

우선 이미지를 벡터화하면, 합성곱을 통해 입력 데이터의 특징을 추출한다.

이 때, 필터(작은 크기의 행렬)와 활성화 함수가 활용된다.

그런 다음 maxpooling을 통해 데이터의 크기를 줄여나간다.

이러한 과정을 여러번 거쳐서 데이터의 크기를 계속 줄여나간다. 

계속해서 크기가 감소한 데이터에는 핵심 데이터만 남게 된다. 

그런 다음 Flatten(numpy에서 제공하는 다차원 배열 공간을 1차원으로 평탄화해주는 함수)로 1차원 배열로 데이터를 정제한다.

최종적으로, cnn의 합성공/풀링층을 거쳐 추출된 고수준 특징을 결합해서 분류/회귀등의 작업에 필요한 형태로 변환한다.

그런 다음, model을 정의하고 학습을 진행시키면 된다. 

cnn은 컴퓨터 비전과 자연어 처리에서 두각을 나타내고 있다.

예를 들어, 이미지 분류/객체 탐지(우리가 했던, 카메라를 통해 길을 탐지해서 자율 주행 실시)/영상 분할/자연어 처리 등에 활용이 된다. 



(cnn에 대한 더 자세한 설명은 3_4_CNN_Convolutional_Neural_Network_ 파일에 적어 두었다.) 



